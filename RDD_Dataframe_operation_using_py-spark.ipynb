{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Apache Spark Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part a) Basic Operations on Resilient Distributed Dataset (RDD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [\"spark\",\"rdd\",\"python\",\"context\",\"create\",\"class\"]\n",
    "list2 = [\"operation\",\"apache\",\"scala\",\"lambda\",\"parallel\",\"partition\"]\n",
    "a = sc.parallelize(list1)\n",
    "b = sc.parallelize(list2)\n",
    "a = a.map(lambda x: (x,1))\n",
    "b = b.map(lambda x: (x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'create',\n",
       " 'context',\n",
       " 'apache',\n",
       " 'operation',\n",
       " 'spark',\n",
       " 'scala',\n",
       " 'partition',\n",
       " 'class',\n",
       " 'rdd',\n",
       " 'parallel',\n",
       " 'lambda']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = a.fullOuterJoin(b).map(lambda x: x[0])\n",
    "x.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache', 'operation', 'scala', 'partition', 'parallel', 'lambda']\n"
     ]
    }
   ],
   "source": [
    "y = a.rightOuterJoin(b).map(lambda x: x[0])\n",
    "print(y.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total number of occurances of s in a :', 3)\n",
      "('total number of occurances of s in b :', 1)\n",
      "('total count of s in a and b is:', 4)\n"
     ]
    }
   ],
   "source": [
    "string1 = \"\".join(word for word in list1)\n",
    "string2 = \"\".join(word for word in list2)\n",
    "list3 = list(string1)\n",
    "list4 = list(string2)\n",
    "c = sc.parallelize(list3)\n",
    "d = sc.parallelize(list4)\n",
    "\n",
    "#map reduce to count occurance of s in a\n",
    "\n",
    "count_a = c.map(lambda x:'s' in x)\n",
    "count_a = count_a.reduce(lambda a, b:a+b)\n",
    "print(\"total number of occurances of s in a :\",count_a)\n",
    "\n",
    "# map reduce to count ocurrance of s in b\n",
    "count_b = d.map(lambda x:'s' in x)\n",
    "count_b = count_b.reduce(lambda a, b:a+b)\n",
    "print(\"total number of occurances of s in b :\",count_b)\n",
    "total_count = count_a + count_b\n",
    "print(\"total count of s in a and b is:\",total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The total count of s in list 1 is :', [3.0])\n",
      "('The total count of s in list 2 is :', [1.0])\n",
      "('The total count of s in both list1 and list2 is :', [4.0])\n"
     ]
    }
   ],
   "source": [
    "aggregate_a = a.flatMap(lambda x: list(x[0]))\n",
    "aggregate_a = aggregate_a.map(lambda x: (x,1)).filter(lambda x: x[0]=='s')\n",
    "aggregate_a = aggregate_a.aggregateByKey((0.0),\n",
    "                (lambda x,y: (x+y)),(lambda m,n:(m+n))).values().collect()\n",
    "\n",
    "print(\"The total count of s in list 1 is :\",aggregate_a)\n",
    "aggregate_b = b.flatMap(lambda x: list(x[0]))\n",
    "aggregate_b = aggregate_b.map(lambda x: (x,1)).filter(lambda x: x[0]=='s')\n",
    "aggregate_b = aggregate_b.aggregateByKey((0.0),\n",
    "                (lambda x,y: (x+y)),(lambda m,n:(m+n))).values().collect()\n",
    "#aggregate_b.values().collect()\n",
    "print(\"The total count of s in list 2 is :\",aggregate_b)\n",
    "\n",
    "total_aggregate = [sum(x) for x in zip(aggregate_a, aggregate_b)]\n",
    "print(\"The total count of s in both list1 and list2 is :\",total_aggregate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b) Basic Operations on DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- points: long (nullable = true)\n",
      " |-- s_id: long (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "sqlContext = SQLContext(sc)\n",
    "student_df = sqlContext.read.json(\"C:\\\\Users\\\\saikiran\\\\Desktop\\\\student.txt\")\n",
    "print student_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|     null|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|  null|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|              null|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|     null|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "student_df.registerTempTable(\"student\")\n",
    "\n",
    "student_df =  sqlContext.sql(\"select * from student\")\n",
    "print(student_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|     null|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|    11|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|              null|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|     null|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fill_values = {column: temp_df.agg({column:\"mean\"}).first()[0] for column in temp_df.columns if column not in ['dob','course','first_name','last_name','s_id']}\n",
    "#replacing null values in points column\n",
    "fill_values = {column: student_df.agg({column:\"mean\"}).first()[0] for column in student_df.columns if column  in ['points']}\n",
    "student_df = student_df.na.fill(fill_values)\n",
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    17|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    16|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|      ---|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    15|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|    11|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|           Unknown|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    19|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|      ---|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Replace null values in last_name and dob\n",
    "student_df = student_df.fillna({'last_name':'---'})\n",
    "student_df.fillna({'dob':\"Unknown\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------+---------+------+----+\n",
      "|            course|               dob|first_name|last_name|points|s_id|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "|Humanities and Art|  October 14, 1983|      Alan|      Joe|    10|   1|\n",
      "|  Computer Science|September 26, 1980|    Martin|  Genberg|    20|   2|\n",
      "|    Graphic Design|     June 12, 1982|     Athur|   Watson|    20|   3|\n",
      "|    Graphic Design|     April 5, 1987|  Anabelle|  Sanberg|    12|   4|\n",
      "|        Psychology|  November 1, 1978|      Kira| Schommer|    11|   5|\n",
      "|          Business|  17 February 1981| Christian|   Kiriam|    10|   6|\n",
      "|  Machine Learning|    1 January 1984|   Barbara|  Ballard|    14|   7|\n",
      "|     Deep Learning|  January 13, 1978|      John|      ---|    10|   8|\n",
      "|  Machine Learning|  26 December 1989|    Marcus|   Carson|    20|   9|\n",
      "|           Physics|  30 December 1987|     Marta|   Brooks|    11|  10|\n",
      "|    Data Analytics|     June 12, 1975|     Holly| Schwartz|    12|  11|\n",
      "|  Computer Science|      July 2, 1985|     April|    Black|    11|  12|\n",
      "|  Computer Science|     July 22, 1980|     Irene|  Bradley|    13|  13|\n",
      "|        Psychology|   7 February 1986|      Mark|    Weber|    12|  14|\n",
      "|       Informatics|      May 18, 1987|     Rosie|   Norman|     9|  15|\n",
      "|          Business|   August 10, 1984|    Martin|   Steele|     7|  16|\n",
      "|  Machine Learning|  16 December 1990|     Colin| Martinez|     9|  17|\n",
      "|    Data Analytics|              null|   Bridget|    Twain|     6|  18|\n",
      "|          Business|      7 March 1980|   Darlene|    Mills|    20|  19|\n",
      "|    Data Analytics|      June 2, 1985|   Zachary|      ---|    10|  20|\n",
      "+------------------+------------------+----------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Updating the points of each students if his point is greater than first deviation of all points\n",
    "\n",
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col,when\n",
    "\n",
    "df_stats = student_df.select(\n",
    "    _mean(col('points')).alias('mean'),\n",
    "    _stddev(col('points')).alias('std')).collect()\n",
    "\n",
    "mean = df_stats[0]['mean']\n",
    "std = df_stats[0]['std']\n",
    "first_std = mean + std\n",
    "student_df = student_df.withColumn(\"points\", \n",
    "          when(col(\"points\")>first_std, 20).\n",
    "          otherwise(col(\"points\")))\n",
    "student_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pdf = student_df.toPandas()\n",
    "print(type(pdf))\n",
    "pdf.hist(\"points\",bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Recommender Dataset with ApacheSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikiran\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+\n",
      "|UserId|MovieId|                 Tag| Timestamp|\n",
      "+------+-------+--------------------+----------+\n",
      "|    15|   4973|          excellent!|1215184630|\n",
      "|    20|   1747|            politics|1188263867|\n",
      "|    20|   1747|              satire|1188263867|\n",
      "|    20|   2424|     chick flick 212|1188263835|\n",
      "|    20|   2424|               hanks|1188263835|\n",
      "|    20|   2424|                ryan|1188263835|\n",
      "|    20|   2947|              action|1188263755|\n",
      "|    20|   2947|                bond|1188263756|\n",
      "|    20|   3033|               spoof|1188263880|\n",
      "|    20|   3033|           star wars|1188263880|\n",
      "|    20|   7438|              bloody|1188263801|\n",
      "|    20|   7438|             kung fu|1188263801|\n",
      "|    20|   7438|           Tarantino|1188263801|\n",
      "|    21|  55247|                   R|1205081506|\n",
      "|    21|  55253|               NC-17|1205081488|\n",
      "|    25|     50|        Kevin Spacey|1166101426|\n",
      "|    25|   6709|         Johnny Depp|1162147221|\n",
      "|    31|     65|        buddy comedy|1188263759|\n",
      "|    31|    546|strangely compelling|1188263674|\n",
      "|    31|   1091|         catastrophe|1188263741|\n",
      "+------+-------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\saikiran\\\\Downloads\\\\ml-10m\\\\ml-10M100K\\\\tags.dat', sep = \"::\", header=None)\n",
    "data.columns = ['UserId', 'MovieId', 'Tag', 'Timestamp']\n",
    "p_schema = StructType([StructField('UserId',LongType(),True),StructField('MovieId',LongType(),True),StructField('Tag',StringType(),True),StructField('Timestamp',StringType(),True)])\n",
    "\n",
    "movie_lens = sqlContext.createDataFrame(data,p_schema)\n",
    "movie_lens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+----------+\n",
      "|UserId|MovieId|                 Tag| Timestamp|  previous|\n",
      "+------+-------+--------------------+----------+----------+\n",
      "|  1806|  43560|              comedy|1147983808|      null|\n",
      "|  1806|  43560|                kids|1147983808|1147983808|\n",
      "|  1806|   7018|            language|1172157899|1147983808|\n",
      "|  1806|   7152|              nudity|1176483953|1172157899|\n",
      "|  1806|   7152|                dark|1176483990|1176483953|\n",
      "|  1806|  44709|        heartwarming|1176485185|1176483990|\n",
      "|  1806|  44199|intelligent thriller|1176485297|1176485185|\n",
      "|  1806|  43936|               tense|1176485376|1176485297|\n",
      "|  1806|  43928|              stupid|1176485429|1176485376|\n",
      "|  1806|  42734|              clever|1176485536|1176485429|\n",
      "|  1806|  40583|       confused plot|1176485722|1176485536|\n",
      "|  1806|  37475|                slow|1176485915|1176485722|\n",
      "|  1806|  36527|                slow|1176485965|1176485915|\n",
      "|  1806|  48043|          weak story|1184762689|1176485965|\n",
      "|  1806|  48043|           dreamlike|1184762699|1184762689|\n",
      "|  1806|  48043|       disappointing|1184762776|1184762699|\n",
      "|  1806|  51834|     chick flick 212|1203867534|1184762776|\n",
      "|  1806|  55290|Very Strong Language|1204564122|1203867534|\n",
      "|  2040|   1377|              action|1189086212|      null|\n",
      "|  2040|   1377|              batman|1189086212|1189086212|\n",
      "+------+-------+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "win = Window.partitionBy(\"UserId\").orderBy([\"UserId\",\"Timestamp\"])\n",
    "movie_lens = movie_lens.withColumn(\"previous\", F.lag(movie_lens.Timestamp).over(win))\n",
    "movie_lens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+----------+-----------+\n",
      "|UserId|MovieId|                 Tag| Timestamp|  previous| difference|\n",
      "+------+-------+--------------------+----------+----------+-----------+\n",
      "|  1806|  43560|              comedy|1147983808|      null|        0.0|\n",
      "|  1806|  43560|                kids|1147983808|1147983808|        0.0|\n",
      "|  1806|   7018|            language|1172157899|1147983808|2.4174091E7|\n",
      "|  1806|   7152|              nudity|1176483953|1172157899|  4326054.0|\n",
      "|  1806|   7152|                dark|1176483990|1176483953|       37.0|\n",
      "|  1806|  44709|        heartwarming|1176485185|1176483990|     1195.0|\n",
      "|  1806|  44199|intelligent thriller|1176485297|1176485185|      112.0|\n",
      "|  1806|  43936|               tense|1176485376|1176485297|       79.0|\n",
      "|  1806|  43928|              stupid|1176485429|1176485376|       53.0|\n",
      "|  1806|  42734|              clever|1176485536|1176485429|      107.0|\n",
      "|  1806|  40583|       confused plot|1176485722|1176485536|      186.0|\n",
      "|  1806|  37475|                slow|1176485915|1176485722|      193.0|\n",
      "|  1806|  36527|                slow|1176485965|1176485915|       50.0|\n",
      "|  1806|  48043|          weak story|1184762689|1176485965|  8276724.0|\n",
      "|  1806|  48043|           dreamlike|1184762699|1184762689|       10.0|\n",
      "|  1806|  48043|       disappointing|1184762776|1184762699|       77.0|\n",
      "|  1806|  51834|     chick flick 212|1203867534|1184762776|1.9104758E7|\n",
      "|  1806|  55290|Very Strong Language|1204564122|1203867534|   696588.0|\n",
      "|  2040|   1377|              action|1189086212|      null|        0.0|\n",
      "|  2040|   1377|              batman|1189086212|1189086212|        0.0|\n",
      "+------+-------+--------------------+----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_lens = movie_lens.withColumn(\"difference\", F.when(F.isnull(movie_lens.Timestamp - movie_lens.previous), 0)\n",
    "                              .otherwise(movie_lens.Timestamp - movie_lens.previous))\n",
    "\n",
    "movie_lens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+----------+-----------+--------+\n",
      "|UserId|MovieId|                 Tag| Timestamp|  previous| difference|Inactive|\n",
      "+------+-------+--------------------+----------+----------+-----------+--------+\n",
      "|  1806|  43560|              comedy|1147983808|      null|        0.0|       0|\n",
      "|  1806|  43560|                kids|1147983808|1147983808|        0.0|       0|\n",
      "|  1806|   7018|            language|1172157899|1147983808|2.4174091E7|       1|\n",
      "|  1806|   7152|              nudity|1176483953|1172157899|  4326054.0|       1|\n",
      "|  1806|   7152|                dark|1176483990|1176483953|       37.0|       0|\n",
      "|  1806|  44709|        heartwarming|1176485185|1176483990|     1195.0|       0|\n",
      "|  1806|  44199|intelligent thriller|1176485297|1176485185|      112.0|       0|\n",
      "|  1806|  43936|               tense|1176485376|1176485297|       79.0|       0|\n",
      "|  1806|  43928|              stupid|1176485429|1176485376|       53.0|       0|\n",
      "|  1806|  42734|              clever|1176485536|1176485429|      107.0|       0|\n",
      "|  1806|  40583|       confused plot|1176485722|1176485536|      186.0|       0|\n",
      "|  1806|  37475|                slow|1176485915|1176485722|      193.0|       0|\n",
      "|  1806|  36527|                slow|1176485965|1176485915|       50.0|       0|\n",
      "|  1806|  48043|          weak story|1184762689|1176485965|  8276724.0|       1|\n",
      "|  1806|  48043|           dreamlike|1184762699|1184762689|       10.0|       0|\n",
      "|  1806|  48043|       disappointing|1184762776|1184762699|       77.0|       0|\n",
      "|  1806|  51834|     chick flick 212|1203867534|1184762776|1.9104758E7|       1|\n",
      "|  1806|  55290|Very Strong Language|1204564122|1203867534|   696588.0|       1|\n",
      "|  2040|   1377|              action|1189086212|      null|        0.0|       0|\n",
      "|  2040|   1377|              batman|1189086212|1189086212|        0.0|       0|\n",
      "+------+-------+--------------------+----------+----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_lens = movie_lens.withColumn(\"Inactive\",  F.when(movie_lens.difference>(30*60),1)\n",
    "                           .otherwise(0))\n",
    "movie_lens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+----------+-----------+--------+----------+\n",
      "|UserId|MovieId|                 Tag| Timestamp|  previous| difference|Inactive|TagSession|\n",
      "+------+-------+--------------------+----------+----------+-----------+--------+----------+\n",
      "|  1806|  43560|              comedy|1147983808|      null|        0.0|       0|         0|\n",
      "|  1806|  43560|                kids|1147983808|1147983808|        0.0|       0|         0|\n",
      "|  1806|   7018|            language|1172157899|1147983808|2.4174091E7|       1|         1|\n",
      "|  1806|   7152|              nudity|1176483953|1172157899|  4326054.0|       1|         2|\n",
      "|  1806|   7152|                dark|1176483990|1176483953|       37.0|       0|         2|\n",
      "|  1806|  44709|        heartwarming|1176485185|1176483990|     1195.0|       0|         2|\n",
      "|  1806|  44199|intelligent thriller|1176485297|1176485185|      112.0|       0|         2|\n",
      "|  1806|  43936|               tense|1176485376|1176485297|       79.0|       0|         2|\n",
      "|  1806|  43928|              stupid|1176485429|1176485376|       53.0|       0|         2|\n",
      "|  1806|  42734|              clever|1176485536|1176485429|      107.0|       0|         2|\n",
      "|  1806|  40583|       confused plot|1176485722|1176485536|      186.0|       0|         2|\n",
      "|  1806|  37475|                slow|1176485915|1176485722|      193.0|       0|         2|\n",
      "|  1806|  36527|                slow|1176485965|1176485915|       50.0|       0|         2|\n",
      "|  1806|  48043|          weak story|1184762689|1176485965|  8276724.0|       1|         3|\n",
      "|  1806|  48043|           dreamlike|1184762699|1184762689|       10.0|       0|         3|\n",
      "|  1806|  48043|       disappointing|1184762776|1184762699|       77.0|       0|         3|\n",
      "|  1806|  51834|     chick flick 212|1203867534|1184762776|1.9104758E7|       1|         4|\n",
      "|  1806|  55290|Very Strong Language|1204564122|1203867534|   696588.0|       1|         5|\n",
      "|  2040|   1377|              action|1189086212|      null|        0.0|       0|         0|\n",
      "|  2040|   1377|              batman|1189086212|1189086212|        0.0|       0|         0|\n",
      "+------+-------+--------------------+----------+----------+-----------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_partition=Window.partitionBy(['UserId']).orderBy(movie_lens['Timestamp']) \n",
    "movie_lens = movie_lens.withColumn('TagSession',F.sum('Inactive').over(temp_partition))\n",
    "movie_lens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|UserId|TagSession|\n",
      "+------+----------+\n",
      "|  1806|         0|\n",
      "|  1806|         0|\n",
      "|  1806|         1|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         2|\n",
      "|  1806|         3|\n",
      "|  1806|         3|\n",
      "|  1806|         3|\n",
      "|  1806|         4|\n",
      "|  1806|         5|\n",
      "|  2040|         0|\n",
      "|  2040|         0|\n",
      "+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#separating out the tagging sesssion of each user\n",
    "movie_lens_tag = movie_lens.select(\"UserId\",\"TagSession\")\n",
    "#counting the tag session foe each user\n",
    "#movie_lens_tag = movie_lens_tag.groupBy(\"UserId\",\"TagSession\").count()\n",
    "movie_lens_tag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+\n",
      "|UserId|TagSession|count|\n",
      "+------+----------+-----+\n",
      "|  1806|         0|    2|\n",
      "|  1806|         1|    1|\n",
      "|  1806|         2|   10|\n",
      "|  1806|         3|    3|\n",
      "|  1806|         4|    1|\n",
      "|  1806|         5|    1|\n",
      "|  2040|         0|    2|\n",
      "| 15437|         0|    1|\n",
      "| 15663|         0|    1|\n",
      "| 15846|         0|    9|\n",
      "| 18295|         0|    1|\n",
      "| 18295|         1|    3|\n",
      "| 18730|         0|    1|\n",
      "| 19141|         0|    1|\n",
      "| 25649|         0|    1|\n",
      "| 25649|         1|    1|\n",
      "| 25649|         2|    1|\n",
      "| 25649|         3|    1|\n",
      "| 27919|         0|    1|\n",
      "| 27919|         1|    2|\n",
      "+------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate the frequency of tagging for each user session\n",
    "movie_lens_tag = movie_lens_tag.groupby(\"UserId\",\"TagSession\").count()\n",
    "movie_lens_tag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+--------------+\n",
      "|UserId|TagSession|count|mean_each_user|\n",
      "+------+----------+-----+--------------+\n",
      "|  1806|         0|    2|           3.0|\n",
      "|  1806|         1|    1|           3.0|\n",
      "|  1806|         2|   10|           3.0|\n",
      "|  1806|         3|    3|           3.0|\n",
      "|  1806|         4|    1|           3.0|\n",
      "|  1806|         5|    1|           3.0|\n",
      "|  2040|         0|    2|           2.0|\n",
      "| 15437|         0|    1|           1.0|\n",
      "| 15663|         0|    1|           1.0|\n",
      "| 15846|         0|    9|           9.0|\n",
      "| 18295|         0|    1|           2.0|\n",
      "| 18295|         1|    3|           2.0|\n",
      "| 18730|         0|    1|           1.0|\n",
      "| 19141|         0|    1|           1.0|\n",
      "| 25649|         0|    1|           1.0|\n",
      "| 25649|         1|    1|           1.0|\n",
      "| 25649|         2|    1|           1.0|\n",
      "| 25649|         3|    1|           1.0|\n",
      "| 27919|         0|    1|           1.5|\n",
      "| 27919|         1|    2|           1.5|\n",
      "+------+----------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find a mean of the tagging frequency of each user.\n",
    "movie_lens_tag_each_mean = movie_lens_tag.groupBy('UserID').agg(F.avg('count').alias('mean_each_user'))\n",
    "movie_lens_tag = movie_lens_tag.join(movie_lens_tag_each_mean, on=['UserID'], how='left_outer')\n",
    "movie_lens_tag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+--------------+------------------+\n",
      "|UserId|TagSession|count|mean_each_user|     std_each_user|\n",
      "+------+----------+-----+--------------+------------------+\n",
      "|  1806|         0|    2|           3.0| 3.521363372331802|\n",
      "|  1806|         1|    1|           3.0| 3.521363372331802|\n",
      "|  1806|         2|   10|           3.0| 3.521363372331802|\n",
      "|  1806|         3|    3|           3.0| 3.521363372331802|\n",
      "|  1806|         4|    1|           3.0| 3.521363372331802|\n",
      "|  1806|         5|    1|           3.0| 3.521363372331802|\n",
      "|  2040|         0|    2|           2.0|               0.0|\n",
      "| 15437|         0|    1|           1.0|               0.0|\n",
      "| 15663|         0|    1|           1.0|               0.0|\n",
      "| 15846|         0|    9|           9.0|               0.0|\n",
      "| 18295|         0|    1|           2.0|1.4142135623730951|\n",
      "| 18295|         1|    3|           2.0|1.4142135623730951|\n",
      "| 18730|         0|    1|           1.0|               0.0|\n",
      "| 19141|         0|    1|           1.0|               0.0|\n",
      "| 25649|         0|    1|           1.0|               0.0|\n",
      "| 25649|         1|    1|           1.0|               0.0|\n",
      "| 25649|         2|    1|           1.0|               0.0|\n",
      "| 25649|         3|    1|           1.0|               0.0|\n",
      "| 27919|         0|    1|           1.5|0.7071067811865476|\n",
      "| 27919|         1|    2|           1.5|0.7071067811865476|\n",
      "+------+----------+-----+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find a standard deviation of the tagging frequency of each user.\n",
    "movie_lens_tag_each_std = movie_lens_tag.groupBy('UserID').agg(F.stddev('count').alias('std_each_user'))\n",
    "movie_lens_tag = movie_lens_tag.join(movie_lens_tag_each_std, on=['UserID'], how='left_outer')\n",
    "movie_lens_tag = movie_lens_tag.fillna({'std_each_user':0.0})\n",
    "movie_lens_tag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('total mean across all users:', 7.300084014358817)\n",
      "('total std across all users:', 22.26429305026497)\n"
     ]
    }
   ],
   "source": [
    "#Find a mean and standard deviation of the tagging frequency for across users.\n",
    "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col,when\n",
    "\n",
    "df_stats2 = movie_lens_tag.select(\n",
    "    _mean(col('count')).alias('mean'),\n",
    "    _stddev(col('count')).alias('std')).collect()\n",
    "\n",
    "mean = df_stats2[0]['mean']\n",
    "std = df_stats2[0]['std']\n",
    "print(\"total mean across all users:\",mean)\n",
    "print(\"total std across all users:\",std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+------------------+------------------+\n",
      "|UserId|TagSession|count|    mean_each_user|     std_each_user|\n",
      "+------+----------+-----+------------------+------------------+\n",
      "|  2030|         0|   72|              72.0|               0.0|\n",
      "| 20729|         0|  110|            52.875| 83.38797018412531|\n",
      "| 20729|         1|  238|            52.875| 83.38797018412531|\n",
      "| 20729|         2|   45|            52.875| 83.38797018412531|\n",
      "| 20729|         3|   10|            52.875| 83.38797018412531|\n",
      "| 20729|         4|    1|            52.875| 83.38797018412531|\n",
      "| 20729|         5|    7|            52.875| 83.38797018412531|\n",
      "| 20729|         6|   11|            52.875| 83.38797018412531|\n",
      "| 20729|         7|    1|            52.875| 83.38797018412531|\n",
      "| 44049|         0|   57|              57.0|               0.0|\n",
      "| 61519|         0|   55|             128.0|103.23759005323593|\n",
      "| 61519|         1|  201|             128.0|103.23759005323593|\n",
      "| 57022|         0|   82|              82.0|               0.0|\n",
      "| 29850|         0|    3|53.333333333333336| 87.17989064763348|\n",
      "| 29850|         1|  154|53.333333333333336| 87.17989064763348|\n",
      "| 29850|         2|    3|53.333333333333336| 87.17989064763348|\n",
      "| 11114|         0|  256|             256.0|               0.0|\n",
      "| 17044|         0|    7|              64.0|  70.8660708661063|\n",
      "| 17044|         1|  106|              64.0|  70.8660708661063|\n",
      "| 17044|         2|  142|              64.0|  70.8660708661063|\n",
      "+------+----------+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_lens_tag.filter(movie_lens_tag['mean_each_user']>(2*std +mean )).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Movielens dataset using Apache Spark MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikiran\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|MovieId|               Title|              Genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|  Animation|Children|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|Comedy|Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|Comedy|Drama|Thri...|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "movie_data = pd.read_csv('C:\\\\Users\\\\saikiran\\\\Downloads\\\\ml-10m\\\\ml-10M100K\\\\movies.dat', sep = \"::\", header=None,parse_dates=False,nrows=100000)\n",
    "movie_data.columns = ['MovieId', 'Title', 'Genres']\n",
    "p_schema = StructType([StructField('MovieId',StringType(),True),StructField('Title',StringType(),True),StructField('Genres',StringType(),True)])\n",
    "\n",
    "movie_lens_mdata = sqlContext.createDataFrame(movie_data,p_schema)\n",
    "movie_lens_mdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saikiran\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+\n",
      "|UserId|MovieId|Ratings|\n",
      "+------+-------+-------+\n",
      "|     1|    122|    5.0|\n",
      "|     1|    185|    5.0|\n",
      "|     1|    231|    5.0|\n",
      "|     1|    292|    5.0|\n",
      "|     1|    316|    5.0|\n",
      "|     1|    329|    5.0|\n",
      "|     1|    355|    5.0|\n",
      "|     1|    356|    5.0|\n",
      "|     1|    362|    5.0|\n",
      "|     1|    364|    5.0|\n",
      "|     1|    370|    5.0|\n",
      "|     1|    377|    5.0|\n",
      "|     1|    420|    5.0|\n",
      "|     1|    466|    5.0|\n",
      "|     1|    480|    5.0|\n",
      "|     1|    520|    5.0|\n",
      "|     1|    539|    5.0|\n",
      "|     1|    586|    5.0|\n",
      "|     1|    588|    5.0|\n",
      "|     1|    589|    5.0|\n",
      "+------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_data = pd.read_csv('C:\\\\Users\\\\saikiran\\\\Downloads\\\\ml-10m\\\\ml-10M100K\\\\ratings.dat', sep = \"::\", header=None,nrows=100000)\n",
    "rating_data = rating_data.iloc[:,0:3]\n",
    "rating_data.columns = ['UserId','MovieId','Ratings']\n",
    "q_schema = StructType([StructField('UserId',StringType(),True),StructField('MovieId',StringType(),True),StructField('Ratings',DoubleType(),True)])\n",
    "\n",
    "movie_lens_rdata = sqlContext.createDataFrame(rating_data,q_schema)\n",
    "movie_lens_rdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+---------+------+-------+\n",
      "|MovieId|         Title|   Genres|UserId|Ratings|\n",
      "+-------+--------------+---------+------+-------+\n",
      "|   1090|Platoon (1986)|Drama|War|    18|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|    34|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|    51|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|    73|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|    78|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|    81|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|    96|    3.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   104|    5.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   107|    3.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   112|    3.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   122|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   123|    5.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   126|    2.5|\n",
      "|   1090|Platoon (1986)|Drama|War|   135|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   137|    3.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   138|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   139|    5.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   140|    4.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   143|    3.0|\n",
      "|   1090|Platoon (1986)|Drama|War|   144|    4.5|\n",
      "+-------+--------------+---------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#joining movies and ratings dataframes to single dataframe\n",
    "\n",
    "movie_rating_data = movie_lens_mdata.join(movie_lens_rdata, on=['MovieId'], how='left_outer')\n",
    "fill_values = {column: movie_rating_data.agg({column:\"mean\"}).first()[0] for column in movie_rating_data.columns if column  in ['Ratings']}\n",
    "movie_rating_data = movie_rating_data.na.fill(fill_values)\n",
    "movie_rating_data = movie_rating_data.fillna({'MovieId':\"Unknown\"})\n",
    "movie_rating_data = movie_rating_data.fillna({'Title':\"Unknown\"})\n",
    "movie_rating_data = movie_rating_data.fillna({'Genres':\"Unknown\"})\n",
    "movie_rating_data = movie_rating_data.fillna({'UserId':\"Unknown\"})\n",
    "movie_rating_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|               Title|Ratings|\n",
      "+--------------------+-------+\n",
      "|Eight Days a Week...|    5.0|\n",
      "|Trouble with Ange...|    5.0|\n",
      "|Marathon Family, ...|    5.0|\n",
      "|    Soul Food (1997)|    5.0|\n",
      "|Seven Chances (1925)|    5.0|\n",
      "| New Age, The (1994)|    5.0|\n",
      "|After Dark, My Sw...|    5.0|\n",
      "|       Gabbeh (1996)|    5.0|\n",
      "|Queen Christina (...|    5.0|\n",
      "|Place in the Sun,...|    5.0|\n",
      "+--------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the movie title which has the maximum average ratings\n",
    "from pyspark.sql.functions import mean, desc\n",
    "#using Map Reduce\n",
    "movie_rating_rdd = movie_rating_data.rdd #convert datafram to rdd\n",
    "average_mean_data = movie_rating_rdd.map(lambda x: (x[1], x[4])) # selects title and ratings\n",
    "average_mean_data = average_mean_data.mapValues(lambda x: (x, 1))#generate count\n",
    "average_mean_data = average_mean_data.reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))#generate sum and count\n",
    "average_mean_data = average_mean_data.mapValues(lambda x: x[0]/x[1]) # calculate the average ratings\n",
    "#average_mean_data = average_mean_data.sortBy(lambda x: x[1], ascending = False)  # sort in descending\n",
    "schema = StructType([StructField('Title',StringType(),True),StructField('Ratings',DoubleType(),True)])\n",
    "average_mean_df = sqlContext.createDataFrame(average_mean_data, schema) #RDD to dataframe\n",
    "average_mean_df = average_mean_df.orderBy(desc(\"Ratings\")) \n",
    "average_mean_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|               Genre|          Ratings|\n",
      "+--------------------+-----------------+\n",
      "|Adventure|Romance...|              5.0|\n",
      "| Documentary|Fantasy|              5.0|\n",
      "|Drama|Mystery|Rom...|             4.75|\n",
      "|Comedy|Drama|Film...|4.666666666666667|\n",
      "|Drama|Film-Noir|H...|              4.5|\n",
      "|Adventure|Drama|F...|              4.5|\n",
      "|Action|Drama|Fant...|              4.5|\n",
      "|Adventure|Drama|S...|              4.5|\n",
      "|Horror|Musical|My...|              4.5|\n",
      "|Children|Comedy|C...|              4.5|\n",
      "+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Find the movie genre with the highest average ratings?\n",
    "#using Map Reduce\n",
    "genre_rating_rdd = movie_rating_data.rdd #convert datafram to rdd\n",
    "average_genre_data = genre_rating_rdd.map(lambda x: (x[2], x[4])) # selects title and ratings\n",
    "average_genre_data = average_genre_data.mapValues(lambda x: (x, 1))#generate count\n",
    "average_genre_data = average_genre_data.reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))#generate sum and count\n",
    "average_genre_data = average_genre_data.mapValues(lambda x: x[0]/x[1]) # calculate the average ratings\n",
    "#average_mean_data = average_mean_data.sortBy(lambda x: x[1], ascending = False)  # sort in descending\n",
    "schema = StructType([StructField('Genre',StringType(),True),StructField('Ratings',DoubleType(),True)])\n",
    "average_genre_df = sqlContext.createDataFrame(average_genre_data, schema)#RDD to dataframe\n",
    "average_genre_df = average_genre_df.orderBy(desc(\"Ratings\")) \n",
    "average_genre_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|UserId|Ratings|\n",
      "+------+-------+\n",
      "|   672|    2.0|\n",
      "|   739|    2.0|\n",
      "|   556|    2.0|\n",
      "|   160|    2.0|\n",
      "|   276|   2.25|\n",
      "|    34|    2.5|\n",
      "|   759|    2.5|\n",
      "|   426|    2.5|\n",
      "|   307|    2.5|\n",
      "|   480|    2.5|\n",
      "+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.\tFind the user who has assign the lowest average ratings among all the users the number of ratings greater than 40?\n",
    "\n",
    "movie_rating_data_tmp = movie_rating_data.groupby(movie_rating_data.UserId, movie_rating_data.Ratings).count()\n",
    "movie_rating_data_tmp = movie_rating_data_tmp.filter(movie_rating_data_tmp['count']>40 )\n",
    "\n",
    "\n",
    "\n",
    "user_rating_rdd = movie_rating_data_tmp.rdd #convert datafram to rdd\n",
    "average_user_data = user_rating_rdd.map(lambda x: (x[0], x[1])) # selects title and ratings\n",
    "average_user_data = average_user_data.mapValues(lambda x: (x, 1))#generate count\n",
    "average_user_data = average_user_data.reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))#generate sum and count\n",
    "#average_user_data = average_user_data.filter(lambda x: len(x[0])>40)\n",
    "\n",
    "average_user_data = average_user_data.mapValues(lambda x: x[0]/x[1]) # calculate the average ratings\n",
    "average_user_data = average_user_data.sortBy(lambda x: x[1], ascending = True)\n",
    "schema = StructType([StructField('UserId',StringType(),True),StructField('Ratings',DoubleType(),True)])\n",
    "average_user_df = sqlContext.createDataFrame(average_user_data, schema)#RDD to dataframe\n",
    "#average_user_df = average_user_df.orderBy(desc(\"Ratings\")) \n",
    "average_user_df.show(10)\n",
    "#print(average_user_data.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
