{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spark MLLIB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.mllib.recommendation import ALS,MatrixFactorizationModel, Rating\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|   1|  31|   2.5|\n",
      "|   1|1029|   3.0|\n",
      "|   1|1061|   3.0|\n",
      "|   1|1129|   2.0|\n",
      "|   1|1172|   4.0|\n",
      "|   1|1263|   2.0|\n",
      "|   1|1287|   2.0|\n",
      "|   1|1293|   2.0|\n",
      "|   1|1339|   3.5|\n",
      "|   1|1343|   2.0|\n",
      "|   1|1371|   2.5|\n",
      "|   1|1405|   1.0|\n",
      "|   1|1953|   4.0|\n",
      "|   1|2105|   4.0|\n",
      "|   1|2150|   3.0|\n",
      "|   1|2193|   2.0|\n",
      "|   1|2294|   2.0|\n",
      "|   1|2455|   2.5|\n",
      "|   1|2968|   1.0|\n",
      "|   1|3671|   3.0|\n",
      "+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reading into Pandas dataframe\n",
    "\n",
    "movie_data = pd.read_csv('C:\\\\Users\\\\saikiran\\\\Downloads\\\\ml-latest-small\\\\ml-latest-small\\\\ratings.csv', sep = \",\")\n",
    "\n",
    "movie_data = movie_data.iloc[:,0:3]\n",
    "p_schema = StructType([StructField('user',IntegerType(),True),StructField('item',IntegerType(),True),StructField('rating',DoubleType(),True)])\n",
    "#converting Pandas dataframe to pyspark dataframe\n",
    "movie_lens = sqlContext.createDataFrame(movie_data,p_schema)\n",
    "movie_lens.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_lens.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.861106985224\n",
      "Root Mean Squared Error =0.9279585040422882\n"
     ]
    }
   ],
   "source": [
    "movie_lens_rdd = movie_lens.rdd\n",
    "X_train, X_test= movie_lens_rdd.randomSplit([0.7, 0.3])\n",
    "# Training the model\n",
    "rank = 5\n",
    "numIterations = 10\n",
    "model = ALS.train(X_train, rank, numIterations, lambda_ = 0.1)\n",
    "testdata = X_test.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = X_test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "\n",
    "# calculating error\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(\"Root Mean Squared Error =\" + str(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, <pyspark.resultiterable.ResultIterable at 0x13586b38>)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping the data based on userid\n",
    "user_item_ratings = movie_lens_rdd.map(lambda r: (int(r[0]),(int(r[1]), r[2])))\n",
    "user_item_ratings = user_item_ratings.groupByKey()\n",
    "user_item_ratings.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, <pyspark.resultiterable.ResultIterable at 0x1356ba20>)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping data based ion itemid\n",
    "item_user_ratings = movie_lens_rdd.map(lambda r: (int(r[1]),(int(r[0]), r[2])))\n",
    "item_user_ratings = item_user_ratings.groupByKey()\n",
    "item_user_ratings.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Items (columns of A matrix): 9066\n",
      "Number of Users (rows of A matrix): 671\n"
     ]
    }
   ],
   "source": [
    "print \"Number of Items (columns of A matrix):\", item_user_ratings.count()\n",
    "print \"Number of Users (rows of A matrix):\", user_item_ratings.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lambda_ = sc.broadcast(0.1) # Regularization parameter\n",
    "n_factors = sc.broadcast(3) # latent factors of User matrix and Item matrix\n",
    "n_iterations = 10 # How many times to iterate over the user and item matrix calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, array([[1.23171603, 0.24265017, 3.10112495]])), (2, array([[4.37840687, 4.60891084, 0.08161432]])), (3, array([[0.42945383, 1.37201934, 1.06338654]])), (4, array([[0.46110377, 4.71009181, 2.64415859]])), (5, array([[0.43231563, 3.88621269, 4.15218662]])), (6, array([[3.61210956, 3.3653311 , 1.96826261]])), (7, array([[3.12599783, 1.32253927, 1.02734962]])), (8, array([[2.82620379, 4.11641606, 3.32292057]])), (9, array([[1.63786827, 0.76335916, 3.47691966]])), (10, array([[1.68042117, 2.39159696, 0.55746939]]))]\n"
     ]
    }
   ],
   "source": [
    "Items = item_user_ratings.map(lambda line: (line[0], 5 * np.random.rand(1, n_factors.value)))\n",
    "print Items.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Items_broadcast = sc.broadcast({\n",
    "  k: v for (k, v) in Items.collect()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[3.86289867 1.00056649 1.97921342]]\n",
      "2 [[1.14372587 0.90837747 2.77237806]]\n",
      "3 [[1.2629488  3.88758693 4.04774345]]\n",
      "4 [[1.40924223 2.54150205 4.71161541]]\n",
      "5 [[2.64275101 0.62759836 1.1176232 ]]\n",
      "6 [[0.32824575 3.59807892 0.32324028]]\n",
      "7 [[3.29227074 1.31497343 4.54320573]]\n",
      "8 [[3.56184697 1.90792738 4.12617274]]\n",
      "9 [[0.90165773 3.74701136 3.99214718]]\n",
      "10 [[0.47373144 1.08796188 3.81162039]]\n",
      "11 [[2.44485905 4.63160819 4.90666724]]\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for k, v in {k: v for (k, v) in Items.collect()}.iteritems():\n",
    "    print k,v\n",
    "    j+=1\n",
    "    if j > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 2.5)\n",
      "(1029, 3.0)\n",
      "(1061, 3.0)\n",
      "(1129, 2.0)\n",
      "(1172, 4.0)\n",
      "(1263, 2.0)\n",
      "(1287, 2.0)\n",
      "(1293, 2.0)\n",
      "(1339, 3.5)\n",
      "(1343, 2.0)\n",
      "(1371, 2.5)\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in user_item_ratings.take(1)[0][1]:\n",
    "    print i\n",
    "    j+=1\n",
    "    if j > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_User(userTuple):\n",
    "    \n",
    "    Itemssquare = np.zeros([n_factors.value,n_factors.value])\n",
    "    for matrixA_item_Tuple in userTuple[1]:\n",
    "        itemRow = Items_broadcast.value[matrixA_item_Tuple[0]][0]\n",
    "        for i in range(n_factors.value):\n",
    "            for j in range(n_factors.value):\n",
    "                Itemssquare[i,j] += float(itemRow[i]) * float(itemRow[j])\n",
    "    leftMatrix = np.linalg.inv(Itemssquare + lambda_.value * np.eye(n_factors.value))\n",
    "    rightMatrix = np.zeros([1,n_factors.value])\n",
    "    for matrixA_item_Tuple in userTuple[1]:\n",
    "        for i in range(n_factors.value):\n",
    "            rightMatrix[0][i] += Items_broadcast.value[matrixA_item_Tuple[0]][0][i] * float(matrixA_item_Tuple[1])\n",
    "    newUserRow = np.dot(leftMatrix, rightMatrix.T).T\n",
    "    return (userTuple[0], newUserRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "Users = user_item_ratings.map(Update_User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, array([[0.44038489, 0.36815262, 0.09943495]]))]\n"
     ]
    }
   ],
   "source": [
    "print Users.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The item matrix is needed in all partitions when solving for rows of User matrix individually\n",
    "Users_broadcast = sc.broadcast({\n",
    "  k: v for (k, v) in Users.collect()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update_Item(itemTuple):\n",
    "    \n",
    "    Userssquare = np.zeros([n_factors.value,n_factors.value])\n",
    "    for matrixA_user_Tuple in itemTuple[1]:\n",
    "        userRow = Users_broadcast.value[matrixA_user_Tuple[0]][0]\n",
    "        for i in range(n_factors.value):\n",
    "            for j in range(n_factors.value):\n",
    "                Userssquare[i,j] += float(userRow[i]) * float(userRow[j])\n",
    "    leftMatrix = np.linalg.inv(Userssquare + lambda_.value * np.eye(n_factors.value))\n",
    "    rightMatrix = np.zeros([1,n_factors.value])\n",
    "    for matrixA_user_Tuple in itemTuple[1]:\n",
    "        for i in range(n_factors.value):\n",
    "            rightMatrix[0][i] += Users_broadcast.value[matrixA_user_Tuple[0]][0][i] * float(matrixA_user_Tuple[1])\n",
    "    newItemRow = np.dot(leftMatrix, rightMatrix.T).T\n",
    "    return (itemTuple[0], newItemRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, array([[2.72138913, 3.98632499, 2.10678328]]))]\n"
     ]
    }
   ],
   "source": [
    "Items = item_user_ratings.map(Update_Item)\n",
    "print Items.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Items_broadcast = sc.broadcast({\n",
    "  k: v for (k, v) in Items.collect()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowSumSquares(userTuple):\n",
    "    userRow = Users_broadcast.value[userTuple[0]]\n",
    "    rowSSE = 0.0\n",
    "    for matrixA_item_Tuple in userTuple[1]:\n",
    "        predictedRating = 0.0\n",
    "        for i in range(n_factors.value):\n",
    "            predictedRating += userRow[0][i] * Items_broadcast.value[matrixA_item_Tuple[0]][0][i]\n",
    "        SE = (float(matrixA_item_Tuple[1]) - predictedRating) ** 2\n",
    "        rowSSE += SE\n",
    "    return rowSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6718622349541447\n",
      "RMSE: 0.8196720288957924\n"
     ]
    }
   ],
   "source": [
    "SSE = user_item_ratings.map(getRowSumSquares).reduce(lambda a, b: a + b)\n",
    "Count = movie_lens_rdd.count()\n",
    "MSE = SSE / Count\n",
    "RMSE = np.sqrt(MSE)\n",
    "print \"MSE:\", MSE\n",
    "print \"RMSE:\", RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Interation =0,RMSE is 0.765117033876:\n",
      "For Interation =1,RMSE is 0.745845231106:\n",
      "For Interation =2,RMSE is 0.734569091586:\n",
      "For Interation =3,RMSE is 0.727264941407:\n",
      "For Interation =4,RMSE is 0.722281954318:\n",
      "For Interation =5,RMSE is 0.71874328772:\n",
      "For Interation =6,RMSE is 0.716015744796:\n",
      "For Interation =7,RMSE is 0.713966656331:\n",
      "For Interation =8,RMSE is 0.712363243951:\n",
      "For Interation =9,RMSE is 0.71108129002:\n"
     ]
    }
   ],
   "source": [
    "for iter in range(n_iterations):\n",
    "    Users = user_item_ratings.map(Update_User)\n",
    "    Users_broadcast = sc.broadcast({k: v for (k, v) in Users.collect()})\n",
    "    Items = item_user_ratings.map(Update_Item)\n",
    "    Items_broadcast = sc.broadcast({k: v for (k, v) in Items.collect()})\n",
    "    SSE = user_item_ratings.map(getRowSumSquares).reduce(lambda a, b: a + b)\n",
    "    MSE = SSE / Count\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print \"For Interation ={},RMSE is {}:\".format(iter,RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 10 iterations the algorithm implementation has obtained a RMSE value of 0.711 and using spark MLLib for 10 iterations, RMSE value obtained is 0.928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
